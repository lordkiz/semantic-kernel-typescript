import { Observable } from "rxjs";
import { TextAIService } from "../types/TextAIService";
import PromptExecutionSettings from "../../orchestration/PromptExecutionSettings";
import Kernel from "../../Kernel";
import StreamingTextContent from "../StreamingTextContent";
import { OpenAiServiceBuilder } from "../openai/OpenAiServiceBuilder";
import { OpenAI as OpenAIClient } from "openai";
import TextContent from "./TextContent";

/**
 * Builder for a TextGenerationService
 */
abstract class Builder extends OpenAiServiceBuilder<
  OpenAIClient,
  TextGenerationService,
  Builder
> {}

/**
 * Interface for text completion services
 */
export abstract class TextGenerationService extends TextAIService {
  /**
   * Get the builder for the TextGenerationService
   *
   * @return The builder
   */
  static Builder = Builder;

  /**
   * Creates a completion for the prompt and settings.
   *
   * @param prompt            The prompt to complete.
   * @param executionSettings Request settings for the completion API
   * @param kernel            The {@code Kernel} containing services, plugins, and other state for
   *                          use throughout the operation.
   * @return Text generated by the remote model
   */
  abstract getTextContentsAsync(
    prompt: string,
    kernel?: Kernel,
    executionSettings?: PromptExecutionSettings
  ): Observable<TextContent>;

  /**
   * Get streaming results for the prompt using the specified execution settings. Each modality
   * may support for different types of streaming contents.
   *
   * @param prompt            The prompt to complete.
   * @param kernel            The {@code Kernel} containing services, plugins, and other state for
   *                          use throughout the operation.
   * @param executionSettings The AI execution settings (optional).
   * @return Streaming list of different completion streaming string updates generated by the
   * remote model
   */
  abstract getStreamingTextContentsAsync(
    prompt: string,
    executionSettings?: PromptExecutionSettings,
    kernel?: Kernel
  ): Observable<StreamingTextContent>;
}
